2024-01-06 16:07:13,332 - algorithms.Algorithm - INFO   - Algorithm options {'data_train_opt': {'batch_size': 10, 'grayscale': True, 'unsupervised': False, 'epoch_size': None, 'random_sized_crop': False, 'dataset_name': 'mnist', 'dataset_len': 100, 'split': 'train'}, 'data_test_opt': {'batch_size': 10, 'grayscale': True, 'unsupervised': False, 'epoch_size': None, 'random_sized_crop': False, 'dataset_name': 'mnist', 'split': 'test'}, 'max_num_epochs': 50, 'out_feat_keys': ['conv2'], 'networks': {'feat_extractor': {'def_file': 'architectures/NetworkInNetwork.py', 'pretrained': './experiments/MNIST_Base_Model/model_net_epoch10', 'opt': {'num_classes': 4, 'num_inchannels': 1, 'num_stages': 4, 'use_avg_on_conv3': False}, 'optim_params': None}, 'classifier': {'def_file': 'architectures/NonLinearClassifier.py', 'pretrained': None, 'opt': {'num_classes': 10, 'nChannels': 12288, 'cls_type': 'MultLayer'}, 'optim_params': {'optim_type': 'sgd', 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True, 'LUT_lr': [(35, 0.1), (70, 0.02), (85, 0.004), (100, 0.0008)]}}}, 'criterions': {'loss': {'ctype': 'CrossEntropyLoss', 'opt': None}}, 'algorithm_type': 'FeatureClassificationModel', 'best_metric': 'prec1', 'exp_dir': '.\\experiments\\MNIST_MultLayerClassifier_on_Base_Model', 'disp_step': 50}
2024-01-06 16:07:13,334 - algorithms.Algorithm - INFO   - Set network feat_extractor
2024-01-06 16:07:13,336 - algorithms.Algorithm - INFO   - ==> Initiliaze network feat_extractor from file architectures/NetworkInNetwork.py with opts: {'num_classes': 4, 'num_inchannels': 1, 'num_stages': 4, 'use_avg_on_conv3': False}
2024-01-06 16:07:13,367 - algorithms.Algorithm - INFO   - ==> Load pretrained parameters from file ./experiments/MNIST_Base_Model/model_net_epoch10:
2024-01-06 16:07:14,642 - algorithms.Algorithm - INFO   - Set network classifier
2024-01-06 16:07:14,642 - algorithms.Algorithm - INFO   - ==> Initiliaze network classifier from file architectures/NonLinearClassifier.py with opts: {'num_classes': 10, 'nChannels': 12288, 'cls_type': 'MultLayer'}
2024-01-06 16:07:14,678 - algorithms.Algorithm - INFO   - Initialize criterion[loss]: CrossEntropyLoss with options: None
2024-01-06 16:07:14,694 - algorithms.Algorithm - INFO   - Initialize optimizer: sgd with params: {'optim_type': 'sgd', 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True, 'LUT_lr': [(35, 0.1), (70, 0.02), (85, 0.004), (100, 0.0008)]} for netwotk: classifier
2024-01-06 16:07:14,694 - algorithms.Algorithm - INFO   - Training epoch [  1 /  50]
2024-01-06 16:07:14,694 - algorithms.Algorithm - INFO   - ==> Set to classifier optimizer lr = 0.1000000000
2024-01-06 16:07:14,694 - algorithms.Algorithm - INFO   - Training: MNIST_MultLayerClassifier_on_Base_Model
2024-01-06 16:11:59,306 - algorithms.Algorithm - INFO   - Algorithm options {'data_train_opt': {'batch_size': 10, 'grayscale': True, 'unsupervised': False, 'epoch_size': None, 'random_sized_crop': False, 'dataset_name': 'mnist', 'dataset_len': 100, 'split': 'train'}, 'data_test_opt': {'batch_size': 10, 'grayscale': True, 'unsupervised': False, 'epoch_size': None, 'random_sized_crop': False, 'dataset_name': 'mnist', 'split': 'test'}, 'max_num_epochs': 50, 'out_feat_keys': ['conv2'], 'networks': {'feat_extractor': {'def_file': 'architectures/NetworkInNetwork.py', 'pretrained': './experiments/MNIST_Base_Model/model_net_epoch10', 'opt': {'num_classes': 4, 'num_inchannels': 1, 'num_stages': 4, 'use_avg_on_conv3': False}, 'optim_params': None}, 'classifier': {'def_file': 'architectures/NonLinearClassifier.py', 'pretrained': None, 'opt': {'num_classes': 10, 'nChannels': 9408, 'cls_type': 'MultLayer'}, 'optim_params': {'optim_type': 'sgd', 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True, 'LUT_lr': [(35, 0.1), (70, 0.02), (85, 0.004), (100, 0.0008)]}}}, 'criterions': {'loss': {'ctype': 'CrossEntropyLoss', 'opt': None}}, 'algorithm_type': 'FeatureClassificationModel', 'best_metric': 'prec1', 'exp_dir': '.\\experiments\\MNIST_MultLayerClassifier_on_Base_Model', 'disp_step': 50}
2024-01-06 16:11:59,308 - algorithms.Algorithm - INFO   - Set network feat_extractor
2024-01-06 16:11:59,309 - algorithms.Algorithm - INFO   - ==> Initiliaze network feat_extractor from file architectures/NetworkInNetwork.py with opts: {'num_classes': 4, 'num_inchannels': 1, 'num_stages': 4, 'use_avg_on_conv3': False}
2024-01-06 16:11:59,334 - algorithms.Algorithm - INFO   - ==> Load pretrained parameters from file ./experiments/MNIST_Base_Model/model_net_epoch10:
2024-01-06 16:12:00,296 - algorithms.Algorithm - INFO   - Set network classifier
2024-01-06 16:12:00,297 - algorithms.Algorithm - INFO   - ==> Initiliaze network classifier from file architectures/NonLinearClassifier.py with opts: {'num_classes': 10, 'nChannels': 9408, 'cls_type': 'MultLayer'}
2024-01-06 16:12:00,354 - algorithms.Algorithm - INFO   - Initialize criterion[loss]: CrossEntropyLoss with options: None
2024-01-06 16:12:00,384 - algorithms.Algorithm - INFO   - Initialize optimizer: sgd with params: {'optim_type': 'sgd', 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True, 'LUT_lr': [(35, 0.1), (70, 0.02), (85, 0.004), (100, 0.0008)]} for netwotk: classifier
2024-01-06 16:12:00,387 - algorithms.Algorithm - INFO   - Training epoch [  1 /  50]
2024-01-06 16:12:00,389 - algorithms.Algorithm - INFO   - ==> Set to classifier optimizer lr = 0.1000000000
2024-01-06 16:12:00,390 - algorithms.Algorithm - INFO   - Training: MNIST_MultLayerClassifier_on_Base_Model
